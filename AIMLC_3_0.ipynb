{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMho5KjNT+2s05IpZz8RzID"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 3.0 Intro to Convolutional Neural Networks\n",
        "\n",
        "References\n",
        "\n",
        "> AI and Machine Learning for Coders - Laurence Moroney\n",
        "\n",
        "> * https://www.oreilly.com/library/view/ai-and-machine/9781492078180/\n",
        "\n",
        "> Kaggle Fashion MNIST\n",
        "\n",
        "> *  https://www.kaggle.com/datasets/zalando-research/fashionmnist\n",
        "\n",
        "> Keras\n",
        "\n",
        "> * https://keras.io\n",
        "\n",
        "> SciPy\n",
        "\n",
        "> * https://scipy.org\n",
        "\n",
        "\n",
        "IDE (Interactive Development Environment)\n",
        "\n",
        ">[Colab](https://colab.research.google.com)"
      ],
      "metadata": {
        "id": "Rw6NZBe5WRMm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our scripts in this worksheet will create a\n",
        " small convolutional neural network. Instead of directly reading the values of each individual pixel this method looks at groups of pixels that consitute features of an image. Let's define the vocabulary that we will be using:\n",
        "\n",
        "> Convolution\n",
        "\n",
        "> * A filter of weights that are used to multiply a pixel with its neighbors to get a new value for the pixel. It is a method used to locate features in an image\n",
        "\n",
        "> * For example pixels can be grouped in 3 x 3 grids (arrays)\n",
        "\n",
        "> * Using a filter with negative values on the left of the grid, positive values on the right, and zeros in the middle will end up removing most of the information from the image except for vertical lines\n",
        "\n",
        "> Pooling\n",
        "\n",
        "> Pooling is the process of eliminating pixels in your image while maintaining the semantics of the content within the image. Pools are groups of arrays (grids). It is a method that is used to enchance image features.\n",
        "\n",
        "> * Consider a box containing the pixels in a monochrome image\n",
        "\n",
        "> * We then group them into 2 × 2 arrays, so in this case the 16 pixels are grouped into four 2 × 2 arrays\n",
        "\n",
        "> * These are called pools\n",
        "\n",
        "> * We then select the maximum value in each of the groups, and reassemble those into a new image\n",
        "\n",
        "> * Thus, the pixels in our example are reduced by 75% (from 16 to 4), with the maximum value from each pool making up the new image.\n",
        "\n",
        "Let's look at some code"
      ],
      "metadata": {
        "id": "fi-EUfm3syWV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "data = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "(training_images, training_labels), (test_images, test_labels) = data.load_data()\n",
        "\n",
        "training_images = training_images.reshape(60000, 28, 28, 1)\n",
        "training_images = training_images / 255.0\n",
        "test_images = test_images.reshape(10000, 28, 28, 1)\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "      tf.keras.layers.Conv2D(64, (3, 3), activation='relu',\n",
        "                  input_shape=(28, 28, 1)),\n",
        "      tf.keras.layers.MaxPooling2D(2, 2),\n",
        "      tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "      tf.keras.layers.MaxPooling2D(2,2),\n",
        "      tf.keras.layers.Flatten(),\n",
        "      tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "      tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "    ])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "       loss='sparse_categorical_crossentropy',\n",
        "       metrics=['accuracy'])\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "\n",
        "model.evaluate(test_images, test_labels)\n",
        "\n",
        "classifications = model.predict(test_images)\n",
        "print(classifications[0])\n",
        "print(test_labels[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5p_a2QiNyINE",
        "outputId": "7e9f8920-677a-4070-ea24-2377db785586"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 103s 54ms/step - loss: 0.4424 - accuracy: 0.8390\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 100s 54ms/step - loss: 0.2955 - accuracy: 0.8914\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 101s 54ms/step - loss: 0.2471 - accuracy: 0.9081\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 99s 53ms/step - loss: 0.2138 - accuracy: 0.9204\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 100s 54ms/step - loss: 0.1872 - accuracy: 0.9299\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2502 - accuracy: 0.9109\n",
            "313/313 [==============================] - 4s 14ms/step\n",
            "[2.9701064e-09 1.0391694e-08 1.5225023e-11 3.2392287e-11 2.6296049e-11\n",
            " 1.5612089e-06 1.9190652e-12 1.8712221e-06 8.4099785e-09 9.9999648e-01]\n",
            "9\n"
          ]
        }
      ]
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM0gz3sAy9QwmDvZdh4gJox"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "2.5 Neural Network Class - Final Draft (July 2023)\n",
        "\n",
        "References\n",
        "\n",
        "> Make Your Own Neural Network by Tariq Rashid\n",
        "\n",
        "> https://github.com/makeyourownneuralnetwork\n",
        "\n",
        "> Numpy\n",
        "\n",
        "> https://numpy.org\n",
        "\n",
        "> Pyt\n",
        "\n",
        "> https://www.python.org\n",
        "\n",
        "> Scipy\n",
        "\n",
        "> https://scipy.org\n",
        "\n",
        "> Wikipedia\n",
        "\n",
        "> https://en.wikipedia.org/wiki/Dot_product\n",
        "\n",
        "> https://en.wikipedia.org/wiki/Transpose\n",
        "\n",
        "IDE\n",
        "> Google Colab\n",
        "\n",
        "> https://colab.research.google.com\n"
      ],
      "metadata": {
        "id": "Ddz01PEZVIId"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "A class is a reuseable blueprint for creating objects.\n",
        "\n",
        "Our draft class will simulate a biological neural network by having three parts that serve to:\n",
        "\n",
        "> initialize - set quantity of input, hidden, & output nodes\n",
        "\n",
        "> train - refine network weights by using training data\n",
        "\n",
        "> query - given input data, provide an answer from the output nodes"
      ],
      "metadata": {
        "id": "fW92NZRQFCN9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here is our 3rd draft, which serves as our starting point for this worksheet"
      ],
      "metadata": {
        "id": "g6_UBGC1orS-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import scipy.special\n",
        "\n",
        "# draft class definition for a neural network\n",
        "class neuralNetwork:\n",
        "\n",
        "  # intialize the neural network\n",
        "  def __init__(self, inputNodes, hiddenNodes, outputNodes, learningRate):\n",
        "    # layers and learning rates\n",
        "    self.iNodes = inputNodes\n",
        "    self.hNodes = hiddenNodes\n",
        "    self.oNodes = outputNodes\n",
        "    self.learnRate = learningRate\n",
        "    # link weights connecting the layers via matrices\n",
        "    self.wih = np.random.normal(0.0, pow(self.iNodes, -0.5), (self.hNodes, self.iNodes))\n",
        "    self.who = np.random.normal(0.0, pow(self.hNodes, -0.5), (self.oNodes, self.hNodes))\n",
        "    # sigmoid activation function\n",
        "    self.activation_function = lambda x: scipy.special.expit(x)\n",
        "    pass\n",
        "\n",
        "  # train the neural network\n",
        "  def train():\n",
        "    pass\n",
        "\n",
        "  # query the neural network\n",
        "  def query(self, inputs_list):\n",
        "    # convert inputs list to 2d array\n",
        "    inputs = np.array(inputs_list, ndmin=2).T\n",
        "    # calculate signals into hidden layer\n",
        "    hidden_inputs = np.dot(self.wih, inputs)\n",
        "    # calculate the signals emerging from hidden layer\n",
        "    hidden_outputs = self.activation_function(hidden_inputs)\n",
        "    # calculate signals into final output layer\n",
        "    final_inputs = np.dot(self.who, hidden_outputs)\n",
        "    # calculate the signals emerging from final output layer\n",
        "    final_outputs = self.activation_function(final_inputs)\n",
        "    return final_outputs\n",
        "\n",
        "# test\n",
        "inputNodes = 3\n",
        "hiddenNodes = 3\n",
        "outputNodes = 3\n",
        "learningRate = 0.3\n",
        "n = neuralNetwork(inputNodes, hiddenNodes, outputNodes, learningRate)\n",
        "n.query([1.0, 0.5, -1.5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8UhaWWE9egc",
        "outputId": "025cbe85-dda6-45ca-c26e-3b09fe3f8229"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.48397255],\n",
              "       [0.41214331],\n",
              "       [0.55126331]])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's work on the training function\n",
        "\n",
        "We will split our efforts into two overarching tasks:\n",
        "\n",
        "> determining the output from a training example\n",
        "\n",
        "> comparing the training ouput against a target output and making adjustments to the link weights\n",
        "\n",
        "We will accomplish the first task via six steps\n",
        "\n",
        "> convert the scalar inputs list to a 2d array\n",
        "\n",
        "> convert the scalar targets list to a 2d array\n",
        "\n",
        "> calculate the signals into the hidden layer\n",
        "\n",
        "> calculate the signals emerging from the hidden layer\n",
        "\n",
        "> calculate the signals into the final output layer\n",
        "\n",
        "> calculate the signals emerging from the final output layer"
      ],
      "metadata": {
        "id": "N94UApfDPkRM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#train the neural network\n",
        "def train(self, inputs_list, targets_list):\n",
        "  # convert the scalar inputs list to 2d array\n",
        "  inputs = np.array(inputs_list, ndmin=2).T\n",
        "  # convert the scalar targets list to a 2d array\n",
        "  targets = np.array(targets_list, ndmin=2).T\n",
        "  # calculate signals into hidden layer\n",
        "  hidden_inputs = np.dot(self.wih, inputs)\n",
        "  # calculate the signals emerging from hidden layer\n",
        "  hidden_outputs = self.activation_function(hidden_inputs)\n",
        "  # calculate signals into final output layer\n",
        "  final_inputs = np.dot(self.who, hidden_outputs)\n",
        "  # calculate the signals emerging from final output layer\n",
        "  final_outputs = self.activation_function(final_inputs)\n",
        "  pass"
      ],
      "metadata": {
        "id": "6cJLIc15BiG3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will accomplish the second task via four steps\n",
        "\n",
        "> output layer error is the (target - actual)\n",
        "\n",
        "> hidden layer error is the output_errors, split by weights, recombined at hidden nodes\n",
        "\n",
        "> update the weights for the links between the hidden and output layers\n",
        "\n",
        "> update the weights for the links between the input and hidden layers"
      ],
      "metadata": {
        "id": "PlCG7RvpVPAn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_errors = targets - final_outputs"
      ],
      "metadata": {
        "id": "Tuy4_aILrDXL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> That’s the difference between the matrices (targets​ - final_outputs​) done element by element"
      ],
      "metadata": {
        "id": "0e2MSHWzrs-O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_errors = np.dot(self.who.T, output_errors)"
      ],
      "metadata": {
        "id": "WPxUG5U-rz53"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> calculate the back-propagated errors for the hidden layer nodes\n",
        "\n",
        "> split the errors according to the connected weights\n",
        "\n",
        "> recombine them for each hidden layer node\n"
      ],
      "metadata": {
        "id": "AAKFg0wksF5I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "self.who += self.learnRate * np.dot((output_errors​ * final_outputs *\n",
        " (1.0 - final_outputs)​), np.transpose(hidden_outputs)​)"
      ],
      "metadata": {
        "id": "u3qEAViWs3p_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> we have what we need to refine the weights at each layer\n",
        "\n",
        "> for the weights between the hidden and final layers, we use the output_errors​\n",
        "\n",
        "> for the weights between the input and hidden layers, we use these hidden_errors​ we just calculated"
      ],
      "metadata": {
        "id": "TUphKlD9tEY2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "self.wih​ += self.learnRate * np.dot((hidden_errors​ * hidden_outputs *\n",
        " (1.0 - hidden_outputs)​), np.transpose(inputs)​)"
      ],
      "metadata": {
        "id": "TKMDmrlhuSYY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> That += simply means increase the preceding variable by the next amount\n",
        "\n",
        "> The learning rate is self.learnRate and simply multiplied with the rest of the expression.\n",
        "\n",
        "> There is a matrix multiplication done by numpy.dot() and the two elements are coloured red and green to show the part related to the error and sigmoids from the next layer, and the transposed outputs from the previous layer"
      ],
      "metadata": {
        "id": "kQnuPX6Uvazc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "So the revised training function is"
      ],
      "metadata": {
        "id": "RZ0VI4sdwWb5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train the neural network\n",
        "def train(self, inputs_list, targets_list):\n",
        "  # convert the scalar inputs list to a 2d array\n",
        "  inputs = np.array(inputs_list, ndmin = 2).T\n",
        "  # convert the scalar targets list to a 2d array\n",
        "  targets = np.array(targets_list, ndmin = 2).T\n",
        "  # calculate signals into the hidden layer\n",
        "  hidden_inputs = np.dot(self.wih, inputs)\n",
        "  # calculate signals emerging from the hidden layer\n",
        "  hidden_outputs = self.activation_function(hidden_inputs)\n",
        "  # calculate signals into final output layer\n",
        "  final_inputs = np.dot(self.who, hidden_outputs)\n",
        "  # calculate signals emerging from the final output layer\n",
        "  final_outputs = self.activation_function(final_inputs)\n",
        "\n",
        "  # output layer error is (target - actual)\n",
        "  output_errors = targets - final_outputs\n",
        "  # hidden layer error\n",
        "  hidden_errors = np.dot(self.who.T, output_errors)\n",
        "  # update the link weights between hidden & output layers\n",
        "  self.who += self.learnRate * np.dot((output_errors * final_outputs *\n",
        "    (1.0 - final_outputs)), np.transpose(hidden_outputs))\n",
        "  # update the link weights between input & hidden layers\n",
        "  self.wih += self.learnRate * np.dot((hidden_errors * hidden_outputs *\n",
        "   (1.0 - hidden_outputs)), np.transpose(inputs))"
      ],
      "metadata": {
        "id": "ou7IoKxSwczs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we will assemble the final draft of the class and take it for a test drive"
      ],
      "metadata": {
        "id": "_cWdIJl0CzJm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import scipy.special\n",
        "\n",
        "# draft class definition for a neural network\n",
        "class neuralNetwork:\n",
        "\n",
        "  # intialize the neural network\n",
        "  def __init__(self, inputNodes, hiddenNodes, outputNodes, learningRate):\n",
        "    # layers and learning rates\n",
        "    self.iNodes = inputNodes\n",
        "    self.hNodes = hiddenNodes\n",
        "    self.oNodes = outputNodes\n",
        "    self.learnRate = learningRate\n",
        "    # link weights connecting the layers via matrices\n",
        "    self.wih = np.random.normal(0.0, pow(self.iNodes, -0.5), (self.hNodes, self.iNodes))\n",
        "    self.who = np.random.normal(0.0, pow(self.hNodes, -0.5), (self.oNodes, self.hNodes))\n",
        "    # sigmoid activation function\n",
        "    self.activation_function = lambda x: scipy.special.expit(x)\n",
        "    pass\n",
        "\n",
        "  # train the neural network\n",
        "  def train(self, inputs_list, targets_list):\n",
        "    # convert the scalar inputs list to a 2d array\n",
        "    inputs = np.array(inputs_list, ndmin = 2).T\n",
        "    # convert the scalar targets list to a 2d array\n",
        "    targets = np.array(targets_list, ndmin = 2).T\n",
        "    # calculate signals into the hidden layer\n",
        "    hidden_inputs = np.dot(self.wih, inputs)\n",
        "    # calculate signals emerging from the hidden layer\n",
        "    hidden_outputs = self.activation_function(hidden_inputs)\n",
        "    # calculate signals into final output layer\n",
        "    final_inputs = np.dot(self.who, hidden_outputs)\n",
        "    # calculate signals emerging from the final output layer\n",
        "    final_outputs = self.activation_function(final_inputs)\n",
        "\n",
        "    # output layer error is (target - actual)\n",
        "    output_errors = targets - final_outputs\n",
        "    # hidden layer error\n",
        "    hidden_errors = np.dot(self.who.T, output_errors)\n",
        "    # update the link weights between hidden & output layers\n",
        "    self.who += self.learnRate * np.dot((output_errors * final_outputs *\n",
        "      (1.0 - final_outputs)), np.transpose(hidden_outputs))\n",
        "    # update the link weights between input & hidden layers\n",
        "    self.wih += self.learnRate * np.dot((hidden_errors * hidden_outputs *\n",
        "      (1.0 - hidden_outputs)), np.transpose(inputs))\n",
        "\n",
        "  # query the neural network\n",
        "  def query(self, inputs_list):\n",
        "    # convert inputs list to 2d array\n",
        "    inputs = np.array(inputs_list, ndmin=2).T\n",
        "    # calculate signals into hidden layer\n",
        "    hidden_inputs = np.dot(self.wih, inputs)\n",
        "    # calculate the signals emerging from hidden layer\n",
        "    hidden_outputs = self.activation_function(hidden_inputs)\n",
        "    # calculate signals into final output layer\n",
        "    final_inputs = np.dot(self.who, hidden_outputs)\n",
        "    # calculate the signals emerging from final output layer\n",
        "    final_outputs = self.activation_function(final_inputs)\n",
        "    return final_outputs\n",
        "\n",
        "# test\n",
        "inputNodes = 3\n",
        "hiddenNodes = 3\n",
        "outputNodes = 3\n",
        "learningRate = 0.3\n",
        "n = neuralNetwork(inputNodes, hiddenNodes, outputNodes, learningRate)\n",
        "n.query([1.0, 0.5, -1.5])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vH55BhO_t1y",
        "outputId": "b57c15ba-a60a-4697-e825-a347dcf2520c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.58834981],\n",
              "       [0.42774484],\n",
              "       [0.36766589]])"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    }
  ]
}

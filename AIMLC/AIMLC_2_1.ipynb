{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOlAxK+dT9et5Lfk5uJJz6P"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "2.1 Intro to Computer Vision\n",
        "\n",
        "References\n",
        "\n",
        "> AI and Machine Learning for Coders - Laurence Moroney\n",
        "\n",
        "> * https://www.oreilly.com/library/view/ai-and-machine/9781492078180/\n",
        "\n",
        "> Kaggle Fashion MNIST\n",
        "\n",
        "> *  https://www.kaggle.com/datasets/zalando-research/fashionmnist\n",
        "\n",
        "> Keras\n",
        "\n",
        "> * https://keras.io\n",
        "\n",
        "\n",
        "IDE (Interactive Development Environment)\n",
        "\n",
        ">[Colab](https://colab.research.google.com)"
      ],
      "metadata": {
        "id": "Rw6NZBe5WRMm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our scripts will recognize items of clothing in an image using an approximation of a biological neural network\n",
        "\n",
        ">We will use the Fashion MNIST database for this work\n",
        "\n",
        "> * https://www.kaggle.com/datasets/zalando-research/fashionmnist\n",
        "\n",
        "> * https://pjreddie.com/projects/mnist-in-csv/\n",
        "\n",
        "> * https://github.com/zalandoresearch/fashion-\n",
        "\n",
        "> * https://engineering.zalando.com\n",
        "\n",
        "> The Fashion MNIST Dataset has the following characteristics\n",
        "\n",
        "> * 60,000 images in the training set\n",
        "\n",
        "> * 10,000 images in the test set\n",
        "\n",
        "> * Each image is associated with a label from 1 of 10 classes\n",
        "\n",
        "> * Column 1 is the class label\n",
        "\n",
        "> * Remaining columns are pixel numbers (784 total)\n",
        "\n",
        "> * Each image is 28 pixels high x 28 pixels wide = 784 pixels\n",
        "\n",
        "> * Each pixel is grey scale (darkness) and has an integer value range from 0 to 255\n"
      ],
      "metadata": {
        "id": "ASL-fYbmXYnV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's take another look at a code snippet that trains a neural network on the Fashion MNIST dataset - We will be training for accuracy this time around\n",
        "\n",
        "> The first line pulls the tensorflow library that we will be using\n",
        "\n",
        "> The third through fifth lines setup a class called myCallback\n",
        "\n",
        "> * In it, we define the on_epoch_end function, which will give us details about the logs for this epoch.\n",
        "\n",
        "> * In these logs is an accuracy value, so all we have to do is see if it is greater than .95 (or 95%); if it is, we can stop training by saying self.model.stop_training = True.\n",
        "\n",
        "> The ninth line creates a callbacks object to be an instance of the myCallback function\n",
        "\n",
        "> The tenth line pulls the dataset that we will be using from keras\n",
        "\n",
        "> The 13th line use keras to split the dataset into two subsets along with labels for each image\n",
        "\n",
        "> The 16th - 17th lines normalize each image. This means scaling from an inital pixel value range of 0 to 255 down to a range of 0 to 1\n",
        "\n",
        "> * The process of normalization improves the performance of the neural network\n",
        "\n",
        "> The 19th - 23rd lines have multiple parts:\n",
        "\n",
        "> * Sequential is used to define the layers of the neural network\n",
        "\n",
        "> * Dense is a common layer type consisting of fully (densely) connected neurons\n",
        "\n",
        "> * We are using the Flatten method to crunch the 2 dimensional input array into a 1 dimensional array or line\n",
        "\n",
        "> * We are using a SWAG of 128 hidden nodes (neurons) and the relu activation function\n",
        "\n",
        "> * We are using 10 output layers (we have 10 different clothing labels - classes) and the softmax activation function\n",
        "\n",
        "> The 25th - 27th lines also have multiple parts:\n",
        "\n",
        "> * The adam optimizer is an evolved version of the stochastic gradient descent optimizer\n",
        "\n",
        "> * the sparse_catagorical_crossentropy loss function is built into TensorFlow that is typically used for datasets with catagories (we have 10 different clothing labels - catagories - classes)\n",
        "\n",
        "> * the accuracy metric reports back on the accuracy of the neural network as it is trained\n",
        "\n",
        "> The 29th - 30th lines specify the epochs and add a callbacks parameter. At the end of every epoch the callback function is called\n",
        "\n",
        "> * Each time a dataset passes through an algorithm, it is said to have completed an epoch and we are using 50 of them here\n",
        "\n",
        "> * Chosing the appropriate number of epochs is a judgement call - too many and the model overfits - too few and accuracy suffers\n",
        "\n"
      ],
      "metadata": {
        "id": "xXW5ahpMcq8U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('accuracy')>0.95):\n",
        "      print(\"\\nReached 95% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "callbacks = myCallback()\n",
        "\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "\n",
        "training_images=training_images/255.0\n",
        "test_images=test_images/255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "        tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "               loss='sparse_categorical_crossentropy',\n",
        "               metrics=['accuracy'])\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=50,\n",
        "           callbacks=[callbacks])\n",
        "\n",
        "# Moroney, Laurence. AI and Machine Learning for Coders (p. 31). O'Reilly Media. Kindle Edition."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nx8pEMMDdXcX",
        "outputId": "c3f7cd11-7d2a-4fc5-a98f-c8e97a399c45"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "1875/1875 [==============================] - 9s 4ms/step - loss: 0.5004 - accuracy: 0.8240\n",
            "Epoch 2/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3742 - accuracy: 0.8637\n",
            "Epoch 3/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3361 - accuracy: 0.8777\n",
            "Epoch 4/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3109 - accuracy: 0.8845\n",
            "Epoch 5/50\n",
            "1875/1875 [==============================] - 8s 5ms/step - loss: 0.2950 - accuracy: 0.8912\n",
            "Epoch 6/50\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2798 - accuracy: 0.8965\n",
            "Epoch 7/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2676 - accuracy: 0.9004\n",
            "Epoch 8/50\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2550 - accuracy: 0.9053\n",
            "Epoch 9/50\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2447 - accuracy: 0.9081\n",
            "Epoch 10/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2359 - accuracy: 0.9119\n",
            "Epoch 11/50\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2293 - accuracy: 0.9144\n",
            "Epoch 12/50\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2230 - accuracy: 0.9165\n",
            "Epoch 13/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2156 - accuracy: 0.9191\n",
            "Epoch 14/50\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2078 - accuracy: 0.9217\n",
            "Epoch 15/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2025 - accuracy: 0.9236\n",
            "Epoch 16/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1968 - accuracy: 0.9266\n",
            "Epoch 17/50\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1901 - accuracy: 0.9277\n",
            "Epoch 18/50\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1853 - accuracy: 0.9303\n",
            "Epoch 19/50\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1797 - accuracy: 0.9322\n",
            "Epoch 20/50\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1741 - accuracy: 0.9344\n",
            "Epoch 21/50\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1701 - accuracy: 0.9364\n",
            "Epoch 22/50\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1663 - accuracy: 0.9369\n",
            "Epoch 23/50\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1622 - accuracy: 0.9386\n",
            "Epoch 24/50\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1605 - accuracy: 0.9398\n",
            "Epoch 25/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1545 - accuracy: 0.9412\n",
            "Epoch 26/50\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1498 - accuracy: 0.9444\n",
            "Epoch 27/50\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1479 - accuracy: 0.9442\n",
            "Epoch 28/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1442 - accuracy: 0.9452\n",
            "Epoch 29/50\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1432 - accuracy: 0.9461\n",
            "Epoch 30/50\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1383 - accuracy: 0.9479\n",
            "Epoch 31/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1363 - accuracy: 0.9477\n",
            "Epoch 32/50\n",
            "1863/1875 [============================>.] - ETA: 0s - loss: 0.1305 - accuracy: 0.9503\n",
            "Reached 95% accuracy so cancelling training!\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1306 - accuracy: 0.9503\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f41f218ac20>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    }
  ]
}

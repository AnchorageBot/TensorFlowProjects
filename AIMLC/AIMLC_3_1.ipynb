{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMp2nLk5Dba7EEEhohdo4SD"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 3.1 Intro to Convolutional Neural Networks\n",
        "\n",
        "References\n",
        "\n",
        "> AI and Machine Learning for Coders - Laurence Moroney\n",
        "\n",
        "> * https://www.oreilly.com/library/view/ai-and-machine/9781492078180/\n",
        "\n",
        "> Kaggle Fashion MNIST\n",
        "\n",
        "> *  https://www.kaggle.com/datasets/zalando-research/fashionmnist\n",
        "\n",
        "> Keras\n",
        "\n",
        "> * https://keras.io\n",
        "\n",
        "> SciPy\n",
        "\n",
        "> * https://scipy.org\n",
        "\n",
        "> Tensorflow\n",
        "\n",
        "> * https://www.tensorflow.org\n",
        "\n",
        "\n",
        "IDE (Interactive Development Environment)\n",
        "\n",
        ">[Colab](https://colab.research.google.com)"
      ],
      "metadata": {
        "id": "Rw6NZBe5WRMm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's look at this code snippet again and then take it apart line by line"
      ],
      "metadata": {
        "id": "_n0Wh9bc2in7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "data = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "(training_images, training_labels), (test_images, test_labels) = data.load_data()\n",
        "\n",
        "training_images = training_images.reshape(60000, 28, 28, 1)\n",
        "training_images = training_images / 255.0\n",
        "\n",
        "test_images = test_images.reshape(10000, 28, 28, 1)\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "      tf.keras.layers.Conv2D(64, (3, 3), activation='relu',\n",
        "                  input_shape=(28, 28, 1)),\n",
        "      tf.keras.layers.MaxPooling2D(2, 2),\n",
        "      tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "      tf.keras.layers.MaxPooling2D(2,2),\n",
        "      tf.keras.layers.Flatten(),\n",
        "      tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "      tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "    ])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "       loss='sparse_categorical_crossentropy',\n",
        "       metrics=['accuracy'])\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "\n",
        "model.evaluate(test_images, test_labels)\n",
        "\n",
        "classifications = model.predict(test_images)\n",
        "print('\\n these values represent the output array ', classifications[0])\n",
        "print('\\n we are using ', test_labels[0], 'clothing labels (classes) to sort the images by')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5p_a2QiNyINE",
        "outputId": "2b1284f7-a38f-4779-f322-e305fe257253"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 106s 56ms/step - loss: 0.4397 - accuracy: 0.8417\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 116s 62ms/step - loss: 0.2923 - accuracy: 0.8922\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 111s 59ms/step - loss: 0.2444 - accuracy: 0.9091\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 104s 55ms/step - loss: 0.2148 - accuracy: 0.9201\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 107s 57ms/step - loss: 0.1874 - accuracy: 0.9305\n",
            "313/313 [==============================] - 5s 16ms/step - loss: 0.2683 - accuracy: 0.9078\n",
            "313/313 [==============================] - 6s 20ms/step\n",
            "\n",
            " these values represent the output array  [9.4602211e-09 5.3570250e-08 3.7102763e-09 1.1184373e-07 2.2372364e-09\n",
            " 8.2171849e-05 1.4163791e-08 5.8850994e-05 4.8686974e-07 9.9985838e-01]\n",
            "\n",
            " we are using  9 clothing labels (classes) to sort the images by\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This line pulls the tensorflow library:\n",
        "\n",
        "> https://www.tensorflow.org"
      ],
      "metadata": {
        "id": "qdtE9iBJ21TS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "1chok5W_3DCs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This line pulls the Fashion MNIST dataset\n",
        "\n",
        "> https://keras.io/api/datasets/fashion_mnist/"
      ],
      "metadata": {
        "id": "0YN_4Uuf4pPD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = tf.keras.datasets.fashion_mnist"
      ],
      "metadata": {
        "id": "fnhMEita5MMT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This line uses the load_data() function to define the train and test image parameters\n",
        "\n",
        "> Tuple of NumPy arrays: (x_train, y_train), (x_test, y_test)\n",
        "\n",
        "> https://keras.io/api/datasets/fashion_mnist/#load_data-function"
      ],
      "metadata": {
        "id": "_b8o5aw557nm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(training_images, training_labels), (test_images, test_labels) = data.load_data()"
      ],
      "metadata": {
        "id": "7R2r6CxW61lY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This line reshapes inputs\n",
        "\n",
        "> Our training dataset consists of 60,000 training images, each 28 × 28 pixels in size\n",
        "\n",
        "> We are using 1 color channel for our grayscale images\n",
        "\n",
        "> We can also use color images with 3 channels (red, green, and blue), with the number indicating the intensity of that color.\n",
        "\n",
        "> https://keras.io/api/layers/reshaping_layers/reshape/"
      ],
      "metadata": {
        "id": "gkqptqo_8f1x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_images = training_images.reshape(60000, 28, 28, 1)"
      ],
      "metadata": {
        "id": "uatojWxS9dyw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This line scales down the pixels in the training images, and the process is called normalization\n",
        "\n",
        "> Pixels normally have a range of values from 0 to 255\n",
        "\n",
        "> We are scaling that value range down to 0 to 1\n",
        "\n",
        "> A smaller pixel value range works well with the activation functions that we use in the neurons (nodes)"
      ],
      "metadata": {
        "id": "aSR-Nv_NUxo1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_images = training_images / 255.0"
      ],
      "metadata": {
        "id": "7OlBCmwJUzEA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This line reshapes inputs\n",
        "\n",
        "> Our training dataset consists of 10,000 test images, each one 28 × 28 pixels in size\n",
        "\n",
        "> We are using 1 color channel for our grayscale images\n",
        "\n",
        "> We can also use color images with 3 channels (red, green, and blue), with the number indicating the intensity of that color.\n",
        "\n",
        "> https://keras.io/api/layers/reshaping_layers/reshape/"
      ],
      "metadata": {
        "id": "2IbD3on2YI-j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_images = test_images.reshape(10000, 28, 28, 1)"
      ],
      "metadata": {
        "id": "bV17vtpIY_7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This line scales down the pixels in the training images, and the process is called normalization\n",
        "\n",
        "> Pixels normally have a range of values from 0 to 255\n",
        "\n",
        "> We are scaling that range down to 0 to 1\n",
        "\n",
        "> A smaller pixel range works well with the activation functions that we use in the neurons (nodes)"
      ],
      "metadata": {
        "id": "jFffvbbQZl_l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_images = test_images / 255.0"
      ],
      "metadata": {
        "id": "PY0IO-89ZuOg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This line specifies the parameters of the neural network layers\n",
        "\n",
        "> Sequential()\n",
        "\n",
        "> * A Sequential model is appropriate for a plain stack of layers where each layer has exactly one input tensor and one output tensor\n",
        "\n",
        "> * https://www.tensorflow.org/api_docs/python/tf/keras/Sequential\n",
        "\n",
        "> * https://www.tensorflow.org/api_docs/python/tf/keras/Sequential\n",
        "\n",
        "> .Conv2D()\n",
        "\n",
        "> * 2D convolution layer (e.g. spatial convolution over images)\n",
        "\n",
        "> * Selectively filters an image for components (features) such as lines/edges\n",
        "\n",
        "> * https://keras.io/api/layers/convolution_layers/convolution2d/\n",
        "\n",
        "> .MaxPooling2D()\n",
        "\n",
        "> * Max pooling operation for 2D spatial data\n",
        "\n",
        "> * Downsamples the input along its spatial dimensions (height and width) by taking the maximum value over an input window (of size defined by pool_size) for each channel of the input\n",
        "\n",
        "> * Reduces the amount of image data and highlights/emphasizes image features\n",
        "\n",
        "> * https://keras.io/api/layers/pooling_layers/max_pooling2d/\n",
        "\n",
        "> .Flatten()\n",
        "\n",
        "> * Flattens the input. Does not affect the batch size.\n",
        "\n",
        "> * https://keras.io/api/layers/reshaping_layers/flatten/\n",
        "\n",
        "> .Dense()\n",
        "\n",
        "> * Just your regular densely-connected NN layer\n",
        "\n",
        "> * https://keras.io/api/layers/core_layers/dense/\n",
        "\n",
        "> nn.relu\n",
        "\n",
        "> * activation function - mimics the firing thresholds of a biological neuron\n",
        "\n",
        "> * https://www.tensorflow.org/api_docs/python/tf/nn/relu\n",
        "\n",
        "> nn.softmax\n",
        "\n",
        "> * activation function - mimics the firing thresholds of a biological neuron\n",
        "\n",
        "> * https://www.tensorflow.org/api_docs/python/tf/nn/softmax\n",
        "\n"
      ],
      "metadata": {
        "id": "XDpwVuB3Z2Vp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "      tf.keras.layers.Conv2D(64, (3, 3), activation='relu',\n",
        "                  input_shape=(28, 28, 1)),\n",
        "      tf.keras.layers.MaxPooling2D(2, 2),\n",
        "      tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "      tf.keras.layers.MaxPooling2D(2,2),\n",
        "      tf.keras.layers.Flatten(),\n",
        "      tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "      tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "    ])"
      ],
      "metadata": {
        "id": "D3SdizCAZ3jn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This line configures the model for training\n",
        "\n",
        "> .compile()\n",
        "\n",
        "> * https://www.tensorflow.org/api_docs/python/tf/keras/Model#compile\n",
        "\n",
        "> optimizer - algorithm selections\n",
        "\n",
        "> * https://www.tensorflow.org/api_docs/python/tf/keras/optimizers\n",
        "\n",
        "> loss - between true labels and predicted labels\n",
        "\n",
        "> * https://www.tensorflow.org/api_docs/python/tf/keras/losses\n",
        "\n",
        "> metrics - List of various metrics to be evaluated by the model during training and testing\n",
        "\n",
        "> * https://www.tensorflow.org/api_docs/python/tf/keras/metrics"
      ],
      "metadata": {
        "id": "O-3_cA2tiny8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "       loss='sparse_categorical_crossentropy',\n",
        "       metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "p8Gv5hKMi192"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This line trains the model for a fixed number of epochs (dataset iterations)\n",
        "\n",
        "> * https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit"
      ],
      "metadata": {
        "id": "fS_oQWM_lbKr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(training_images, training_labels, epochs=5)"
      ],
      "metadata": {
        "id": "jK0fh43sldRs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This line returns the loss value & metrics values for the model in test mode.\n",
        "\n",
        "> * https://www.tensorflow.org/api_docs/python/tf/keras/Model#evaluate"
      ],
      "metadata": {
        "id": "J1K67QMXl8Gg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test_images, test_labels)"
      ],
      "metadata": {
        "id": "O1hCTmyhmGKd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This line generates output predictions for the input samples\n",
        "\n",
        "> * https://www.tensorflow.org/api_docs/python/tf/keras/Model#predict"
      ],
      "metadata": {
        "id": "TzdxCpfymVNf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifications = model.predict(test_images)"
      ],
      "metadata": {
        "id": "rhWZezNdmZpZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}

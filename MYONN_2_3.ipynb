{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNYm6liRLLdJV1817yJR9/n"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "2.3 Neural Network Class - 2nd Draft (July 2023)\n",
        "\n",
        "References\n",
        "\n",
        "> Make Your Own Neural Network by Tariq Rashid\n",
        "\n",
        "> https://github.com/makeyourownneuralnetwork\n",
        "\n",
        "> Numpy\n",
        "\n",
        "> https://numpy.org/doc/stable/reference/random/generated/numpy.random.normal.html\n",
        "\n",
        "> https://numpy-ml.readthedocs.io/en/latest/numpy_ml.neural_nets.activations.html\n",
        "\n",
        "> Scipy\n",
        "\n",
        "> https://docs.scipy.org/doc/scipy/reference/generated/scipy.special.expit.html\n",
        "\n",
        "> Python\n",
        "\n",
        "> https://docs.python.org/3/library/functions.html#pow\n",
        "\n",
        "> https://docs.python.org/3/tutorial/controlflow.html#lambda-expressions\n",
        "\n",
        "IDE\n",
        "> Google Colab\n",
        "\n",
        "> https://colab.research.google.com\n"
      ],
      "metadata": {
        "id": "Ddz01PEZVIId"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "A class is a reuseable blueprint for creating objects.\n",
        "\n",
        "Our draft class will simulate a biological neural network by having three parts that serve to:\n",
        "\n",
        "> initialize - set quantity of input, hidden, & output nodes\n",
        "\n",
        "> train - refine network weights by using training data\n",
        "\n",
        "> query - given input data, provide an answer from the output nodes"
      ],
      "metadata": {
        "id": "fW92NZRQFCN9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here is our first draft\n",
        "\n",
        "This draft includes an initialization function with:\n",
        "\n",
        "> input nodes\n",
        "\n",
        "> hidden nodes\n",
        "\n",
        "> output nodes\n",
        "\n",
        "> learning rate"
      ],
      "metadata": {
        "id": "y7rXMKCmG-AC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# draft class definition for a neural network\n",
        "class neuralNetwork:\n",
        "\n",
        "  # initialize the neural network\n",
        "  def __init__(self, inputNodes, hiddenNodes, outputNodes, learningRate):\n",
        "    self.iNodes = inputNodes\n",
        "    self.hNodes = hiddenNodes\n",
        "    self.oNodes = outputNodes\n",
        "    self.learnRate = learningRate\n",
        "    pass\n",
        "\n",
        "  # train the neural network\n",
        "  def train():\n",
        "    pass\n",
        "\n",
        "  # query the neural network\n",
        "  def query():\n",
        "    pass"
      ],
      "metadata": {
        "id": "V6Q9PmxfHcC9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's revise and update by adding link weights to our initialization function\n",
        "\n",
        "Recall that we need to:\n",
        "\n",
        "> generate a matrix for weights linking the input and hidden layers (wih)\n",
        "\n",
        "> generate a matrix for weights linking the hidden and output layers (who)\n"
      ],
      "metadata": {
        "id": "qZU6CSKCq17m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "self.wih = np.random.normal(0.0, pow(self.iNodes,-0.5), (self.hNodes, self.iNodes))\n",
        "\n",
        "self.who = np.random.normal(0.0, pow(self.hNodes, -0.5), (self.oNodes, self.hNodes))"
      ],
      "metadata": {
        "id": "hbLfpZH3rD2_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So what do these functions mean?\n",
        "\n",
        "normal: The numpy library includes a normal distribution function (from the docs):\n",
        "\n",
        "> The probability density function of the normal distribution, first derived by De Moivre and 200 years later by both Gauss and Laplace independently, is often called the bell curve because of its characteristic shape\n",
        "\n",
        "> The normal distributions occurs often in nature. For example, it describes the commonly occurring distribution of samples influenced by a large number of tiny, random disturbances, each with its own unique distribution\n",
        "\n",
        "pow: The python library includes a power function (from the docs):\n",
        "\n",
        "> pow(base, exp, mod=None)\n",
        "\n",
        "> Return base to the power exp; if mod is present, return base to the power exp, modulo mod (computed more efficiently than pow(base, exp) % mod)"
      ],
      "metadata": {
        "id": "JpC7Gf6JggZk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we are going to think about, in a simplified way, how a neuron works\n",
        "\n",
        "> Neuron receives signals\n",
        "\n",
        "> Signals do/do not exceed a threshold value\n",
        "\n",
        "> Neuron does/does not fire\n",
        "\n",
        "We can simulate this activity with a mathematical function called the sigmoid activation function"
      ],
      "metadata": {
        "id": "h9T1FSidqimS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "self.activation_function = lambda​ x: scipy.special.expit(x)"
      ],
      "metadata": {
        "id": "EjDBDvwkvUc8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is a lamda function?\n",
        "\n",
        "From the docs:\n",
        "\n",
        "> Small anonymous functions can be created with the lambda keyword\n",
        "\n",
        "> Lambda functions can be used wherever function objects are required\n",
        "\n",
        "> They are syntactically restricted to a single expression"
      ],
      "metadata": {
        "id": "kF9jzTOV1z1p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here is our revised draft"
      ],
      "metadata": {
        "id": "g6_UBGC1orS-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import scipy.special\n",
        "\n",
        "# draft class definition for a neural network\n",
        "class neuralNetwork:\n",
        "\n",
        "  # initialize the neural network\n",
        "  def __init__(self, inputNodes, hiddenNodes, outputNodes, learningRate):\n",
        "    # layers and learning rate\n",
        "    self.iNodes = inputNodes\n",
        "    self.hNodes = hiddenNodes\n",
        "    self.oNodes = outputNodes\n",
        "    self.learnRate = learningRate\n",
        "    # link weights connecting the layers via matrices\n",
        "    self.wih = np.random.normal(0.0, pow(self.iNodes, -0.5), (self.iNodes, self.hNodes))\n",
        "    self.who = np.random.normal(0.0, pow(self.hNodes, -0.5), (self.oNodes, self.hNodes))\n",
        "    # sigmoid activation function\n",
        "    self.activation_function = lambda​ x: scipy.special.expit(x)\n",
        "    pass\n",
        "\n",
        "  # train the neural network\n",
        "  def train():\n",
        "    pass\n",
        "\n",
        "  # query the neural network\n",
        "  def query():\n",
        "    pass\n"
      ],
      "metadata": {
        "id": "vKwq8GyejaER"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}